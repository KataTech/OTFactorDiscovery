{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABAK: Initialize k-means with random assignments for all points (peppered); this is the best since it is the most likely???\n",
    "# Assigning the centers first is fastest; Assigning the points first is more precise (less likely to get to a local minimum)\n",
    "\n",
    "# Quality: Measure how much variability is left after transporting\n",
    "# \n",
    "\n",
    "# TABAK: You can do something to predict failure to local minimum; you could just sum the distances after initializing\n",
    "# Andrew's clarification: SO you're saying that in our philosophy, the way of deciding which clustering (after a loop) is best is to see which minimizes the variability via transport\n",
    "\n",
    "# Daniel: Desert\n",
    "# TABAK: Try Fermat distance to cross the desert\n",
    "\n",
    "# Andrew: Interesting to determine if mean or median is better depending on the type of distribution (e.g. the multiple datasets that Daniel showed last name)\n",
    "# TABAK: Two questions here: When is the optimal solution better (even if hard to find)? When is it easy to find a reasonably good solution?\n",
    "\n",
    "# Andrew: Maybe loop your current side-by-side thousands of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Initialization: Every ~60 seeds, k-means misplaces the third centroid (i.e. no assignments or split)\n",
    "# ++ Initialization w.r.t custom costs: Every ~10 seeds, the k-medians splits the third centroid\n",
    "# ++ Initialization w.r.t HARD-CODED squared_euclidean cost: One never does better than the other!\n",
    "# ++ Initialization w.r.t HARD-CODED euclidean^9 cost: One never does better than the other! Failure is even rarer."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
